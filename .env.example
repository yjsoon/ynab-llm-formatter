# Choose your LLM provider: "googleaistudio", "openrouter", "z.ai", or "lm-studio"

# === OPTION 1: Google AI Studio (DEFAULT - fastest and most accurate) ===
LLM_PROVIDER=googleaistudio
GOOGLEAISTUDIO_API_KEY=your_google_ai_studio_api_key_here
GOOGLEAISTUDIO_MODEL=gemini-2.5-flash-lite

# Valid Google AI Studio models:
# - gemini-2.5-flash-lite
# - gemini-2.5-flash
# - gemini-2.5-pro

# === OPTION 2: OpenRouter (RECOMMENDED - has model dropdown in UI) ===
# LLM_PROVIDER=openrouter
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# Top performing models (ranked by speed):
# 1. Gemini 2.5 Flash Lite - 3.95s
# OPENROUTER_MODEL=google/gemini-2.5-flash-lite

# 2. Pixtral 12B - 5.64s
# OPENROUTER_MODEL=mistralai/pixtral-12b

# 3. Claude 3 Haiku - 6.80s
# OPENROUTER_MODEL=anthropic/claude-3-haiku

# 4. UI-TARS 1.5 7B - 12.26s
# OPENROUTER_MODEL=bytedance/ui-tars-1.5-7b

# 5. Llama 4 Scout - 12.52s (FREE)
# OPENROUTER_MODEL=meta-llama/llama-4-scout:free

# 6. GPT-4o Mini - 15.38s
# OPENROUTER_MODEL=openai/gpt-4o-mini

# 7. Qwen 2.5 VL 7B - 15.57s
# OPENROUTER_MODEL=qwen/qwen-2.5-vl-7b-instruct

# 8. Llama 3.2 11B Vision - 18.69s
# OPENROUTER_MODEL=meta-llama/llama-3.2-11b-vision-instruct

# 9. Gemma 3 27B - 19.45s (FREE)
# OPENROUTER_MODEL=google/gemma-3-27b-it:free

# 10. Qwen 2.5 VL 32B - 20.13s (FREE)
# OPENROUTER_MODEL=qwen/qwen2.5-vl-32b-instruct:free

# Default model (can be overridden in UI dropdown):
# OPENROUTER_MODEL=google/gemini-2.5-flash-lite


# === OPTION 3: Z.AI Configuration ===
# LLM_PROVIDER=z.ai
# Z_AI_API_KEY=your_z_ai_api_key_here
# Z_AI_API_URL=https://api.z.ai


# === OPTION 4: LM Studio (Local) ===
# LLM_PROVIDER=lm-studio
# LM_STUDIO_URL=http://localhost:1234/v1
# LM_STUDIO_MODEL=qwen2.5-vl-7b-instruct